#+TITLE: Harley Wiltzer
#+AUTHOR: Harley Wiltzer
#+OPTIONS: title:nil toc:nil num:nil
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="./assets/css/homepage.css"/>
#+HTML_HEAD_EXTRA: <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin="anonymous" referrerpolicy="no-referrer" />

#+INCLUDE: "./header.org"

* Harley Wiltzer
:PROPERTIES:
:class: coords-name
:END:
#+BEGIN_coordinates
- PhD Student, McGill University & Mila
- @@html:<icon class="fa-solid fa-envelope-open"></icon>@@ =harley.wiltzer@mail.mcgill.ca=
- @@html:<icon class="fa-brands fa-github"></icon>@@ [[https://github.com/harwiltz][harwiltz]]
- @@html:<icon class="fa-solid fa-pen-nib"></icon>@@ [[./assets/AcademicCV.pdf][CV]] (last updated November 2024)
#+END_coordinates

** Research
#+BEGIN_research-list
1. [[https://arnavkj1995.github.io/SFM][Non-Adversarial Inverse Reinforcement Learning via Successor Feature
   Matching]]. @@html:<br/>@@
   Arnav Kumar Jain, *Harley Wiltzer*, Jesse Farebrother, Irina Rish, Glen
   Berseth, Sanjiban Choudhury @@html:<br/>@@
   Preprint, 2024
   #+BEGIN_paperlinks
   [[https://arxiv.org/pdf/2411.07007][pdf]] / [[https://github.com/arnavkj1995/SFM][code]]
   #+END_paperlinks
2. /[[https://arxiv.org/abs/2410.11022][Action Gaps and Advantages in Continuous-Time Distributional Reinforcement
   Learning]]/. @@html:<br/>@@
   *Harley Wiltzer**, Marc G. Bellemare, David Meger, Patrick Shafto, Yash
   Jhaveri* @@html:<br/>@@
   To appear at Neural Information Processing Systems (NeurIPS), 2024
   #+BEGIN_paperlinks
   [[https://arxiv.org/pdf/2410.11022][pdf]] / [[https://github.com/harwiltz/distributional-superiority][code]] / [[https://cs.mcgill.ca/~hwiltz/dsup-presentation][slides]]
   #+END_paperlinks
3. /[[https://arxiv.org/abs/2409.00328][Foundations of Multivariate Distributional Reinforcement Learning]]/. @@html:
   <br/>@@
   *Harley Wiltzer*, Jesse Farebrother, Arthur Gretton, Mark Rowland @@html:
   <br/>@@
   To appear at Neural Information Processing Systems (NeurIPS), 2024
   #+BEGIN_paperlinks
   [[https://arxiv.org/pdf/2409.00328][pdf]] / [[https://cs.mcgill.ca/~hwiltz/mvdrl-neurips][slides]]
   #+END_paperlinks
4. /[[https://openreview.net/pdf?id=hAH6ZBLOAB][Simplifying Constraint Inference with Inverse Reinforcement Learning]]/.
   @@html:<br/>@@
   Adriana Hugessen, *Harley Wiltzer*, Glen Berseth @@html:<br/>@@
   To appear at Neural Information Processing Systems (NeurIPS), 2024
   #+BEGIN_paperlinks
   [[https://openreview.net/pdf?id=T5Cerv7PT2][pdf]] / [[https://github.com/ahugs/simple-icrl][code]]
   #+END_paperlinks
5. /[[https://deepmind.google/research/publications/44717/][A
   Distributional Analogue to the Successor Representation]]/. @@html:
   <br/>@@
   *Harley Wiltzer**, Jesse Farebrother*, Arthur Gretton, Yunhao Tang,
   Andre Barreto, Will Dabney, Marc G. Bellemare, Mark Rowland @@html:
   <br/>@@
   International Conference on Machine Learning (ICML), 2024
   @@html:<span class="spotlight">@@ Spotlight (top 3.5%)@@html:</span>@@
   #+BEGIN_paperlinks
   [[https://arxiv.org/pdf/2402.08530.pdf][pdf]] / [[https://github.com/JesseFarebro/distributional-sr][code]] / [[https://cs.mcgill.ca/~hwiltz/dsm-presentation][slides]]
   #+END_paperlinks
6. /[[https://arxiv.org/abs/2309.14597][Policy Optimization in a Noisy
   Neighborhood: On Return Landscapes in Continuous
   Control]]/. @@html: <br/>@@
   Nate Rahn*, Pierluca D'Oro*, *Harley Wiltzer*, Pierre-Luc Bacon,
   Marc G. Bellemare @@html: <br/>@@
   Neural Information Processing Systems (NeurIPS), 2023
   #+BEGIN_paperlinks
   [[https://arxiv.org/pdf/2309.14597][pdf]] / [[https://github.com/nathanrahn/return-landscapes][code]]
   #+END_paperlinks
7. /[[https://arxiv.org/abs/2205.12184][Distributional Hamilton-Jacobi-Bellman Equations for
   Continuous-Time Reinforcement Learning]]/. @@html: <br/>@@
   *Harley Wiltzer*, David Meger, Marc G. Bellemare @@html: <br/>@@
   International Conference on Machine Learning (ICML), 2022
   @@html:<span class="spotlight">@@ Spotlight @@html:</span>@@
8. [[./assets/thesis-msc.pdf][On the Evolution of Return Distributions in Continuous-Time
   Reinforcement Learning]]. @@html: <br/>@@
   M.Sc. Thesis.
#+END_research-list

** Talks
#+BEGIN_research-list
1. [[https://www.youtube.com/watch?v=2Cc-2xT2-3k][Distributional Hamilton-Jacobi-Bellman Equations for
   Continuous-Time Reinforcement Learning]]. @@html: <br/>@@
   [[https://sites.google.com/view/rltheoryseminars/upper-bound-workshop?authuser=0][Theory of Reinforcement Learning Workshop]], University of Alberta
#+END_research-list

** Rants
#+BEGIN_SRC elisp :exports results :results raw
(let* ((post-dirs (reverse (directory-files "./posts" nil "^[^.]")))
       (dirs (mapcar (lambda (d) (concat "./posts/" d)) post-dirs))
       (bufs (mapcar (lambda (d) (find-file-noselect (concat d "/index.org"))) dirs))
       (titles (mapcar
		(lambda (b) (with-current-buffer b
			      (car (plist-get (org-export-get-environment) :title))))
		bufs))
       (entries (cl-mapcar (lambda (d x) (concat "[[" d "/index.org][" x "]]"))
			   dirs titles)))
  (concat
   "#+BEGIN_post-list\n"
   (mapconcat
    (lambda (x) (concat "1. " x))
    entries
    "\n") "\n"
   "#+END_post-list\n"))
#+END_SRC
